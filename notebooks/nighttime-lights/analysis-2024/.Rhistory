# Myanmar: 2024 Update
# Filepaths --------------------------------------------------------------------
db_dir <- file.path("~", "Dropbox", "World Bank", "Side Work", "Myanmar Economic Monitor")
data_dir      <- file.path(db_dir, "data")
ntl_bm_dir    <- file.path(data_dir, "Nighttime Lights BlackMarble")
gas_flare_dir <- file.path(data_dir, "Global Gas Flaring 2023")
gadm_dir      <- file.path(data_dir, "GADM")
gdp_dir       <- file.path(data_dir, "GDP")
wdi_dir       <- file.path(data_dir, "WDI")
# Packages ---------------------------------------------------------------------
library(dplyr)
library(readr)
library(janitor)
library(raster)
library(sf)
library(stringr)
library(readxl)
library(exactextractr)
#library(blackmarbler)
library(geodata)
library(lubridate)
library(rgeos)
library(leaflet)
library(leaflet.extras)
library(ggplot2)
library(ggpubr)
library(tidyr)
library(purrr)
library(stargazer)
library(furrr)
library(stringr)
library(rhdf5)
library(raster)
library(dplyr)
library(sf)
library(lubridate)
library(WDI)
library(broom)
library(blackmarbler)
# Aggregate Nighttime Lights
# Do if make changes to how data processed and need to start from scratch
DELETE_DIR <- F
if(DELETE_DIR){
unlink(file.path(ntl_bm_dir, "FinalData", "aggregated"), recursive = T)
dir.create(file.path(ntl_bm_dir, "FinalData", "aggregated"))
}
# Prep SEZ ---------------------------------------------------------------------
sez_sf <- read_sf(file.path(data_dir, "SEZ", "RawData", "industrial__special_economic_zones_sept2019.shp"))
sez_sf <- sez_sf %>% st_buffer(dist = 2.5)
# Loop through ROIs ------------------------------------------------------------
for(adm_level in rev(c("bound1", "bound2", "sez", "0", "1", "2", "3"))){
if(adm_level == "sez"){
roi_sf <- sez_sf
} else if(adm_level == "bound1"){
roi_sf <- read_sf(file.path(data_dir, "Boundaries", "RawData", "mmr_polbnda_adm1_250k_mimu.shp"))
} else if(adm_level == "bound2"){
roi_sf <- read_sf(file.path(data_dir, "Boundaries", "RawData", "mmr_polbnda_adm2_250k_mimu_1.shp"))
} else{
roi_sf <- read_sf(file.path(gadm_dir, "rawdata", paste0("gadm41_MMR_",adm_level,".json")))
}
# Loop through product -------------------------------------------------------
# VNP46A2 = daily
# VNP46A3 = monthly
# VNP46A4 = annually
for(product in c("VNP46A4", "VNP46A3")){
## Make directory to export files - organized by ROI and prduct
OUT_DIR <- file.path(ntl_bm_dir, "FinalData", "aggregated", paste0("adm", adm_level, "_", product))
dir.create(OUT_DIR)
# Loop through rasters -----------------------------------------------------
r_name_vec <- file.path(ntl_bm_dir, "FinalData", paste0(product, "_rasters")) %>% list.files()
for(r_name_i in r_name_vec){
OUT_FILE <- file.path(OUT_DIR, r_name_i %>% str_replace_all(".tif", ".Rds"))
## Check if file exists
if(!file.exists(OUT_FILE)){
## Load raster and create rasters for just gas flaring and non gas flaring locations
r <- raster(file.path(ntl_bm_dir, "FinalData", paste0(product, "_rasters"), r_name_i))
## Extract data
ntl_df <- exact_extract(r, roi_sf, fun = c("mean", "median", "sum"))
roi_sf$ntl_bm_mean   <- ntl_df$mean
roi_sf$ntl_bm_median <- ntl_df$median
roi_sf$ntl_bm_sum    <- ntl_df$sum
## Prep for export
roi_df <- roi_sf %>%
st_drop_geometry()
## Add date
if(product == "VNP46A2"){
year <- r_name_i %>% substring(12,15) %>% as.numeric()
day  <- r_name_i %>% substring(12,21)
date_r <- r_name_i %>%
str_replace_all("VNP46A2_t", "") %>%
str_replace_all(".tif", "") %>%
str_replace_all("_", "-") %>%
paste0("-01") %>%
ymd()
}
if(product == "VNP46A3"){
date_r <- r_name_i %>%
str_replace_all("VNP46A3_t", "") %>%
str_replace_all(".tif", "") %>%
str_replace_all("_", "-") %>%
paste0("-01") %>%
ymd()
}
if(product == "VNP46A4"){
# Just grab year
date_r <- r_name_i %>%
str_replace_all("VNP46A4_t", "") %>%
str_replace_all(".tif", "") %>%
as.numeric()
}
roi_df$date <- date_r
## Export
saveRDS(roi_df, OUT_FILE)
}
}
}
}
# PSV Rider Feedback
# Settings ---------------------------------------------------------------------
#### CODE TO RUN
RUN_CODE <- F # If F, doesn't run any code, no matter the below settings
PROCESS_SENSOR_DATA        <- F # Download and clean sensor data (takes a while)
PROCESS_SENSOR_SURVEY_DATA <- F # Clean survey data. RUN STATA MASTER FIRST TO DOWNLOAD DATA.
#### Other
# Relevant for sensor data. If F, checks if data has already been downloaded. If
# already downloaded, skips downloading it. Set to T if want to redownload data.
OVERWRITE_EXTRACTED_DATA <- F
# Authenticate Google Sheets ---------------------------------------------------
if(F){
# Code for processing sensor survey data uploads some data to google sheets
# (so the sensor company can see issues with the survey that they can correct).
# Can run these two lines to make sure google sheets in authenticated.
# Relevant for: 03_check_all_surveys_entered_compare_wialon.R
library(googlesheets4)
gs4_auth()
}
# Filepaths --------------------------------------------------------------------
#### Root
# Rob (Personal Comptuer)
if(Sys.info()[["user"]] == "robmarty"){
dropbox_dir <- "~/Dropbox/World Bank/IEs/PSV Rider Feedback"
#db_pii_dir  <- "/Volumes/PSV_Rider_Feedback_PII"
db_pii_dir <- "~/Documents/World Bank/PSV Rider Feedback"
#onedrive_dir <- "~/Dropbox/World Bank/IEs/PSV Rider Feedback"
github_dir <- "~/Documents/Github/PSV-Rider-Feedback/"
}
# Rob (WB Computer)
if(Sys.info()[["user"]] == "WB521633"){
dropbox_dir <- "C:/Users/wb521633/Dropbox/World Bank/IEs/PSV Rider Feedback"
github_dir <- "C:/Users/wb521633/Documents/Github/PSV-Rider-Feedback/"
onedrive_dir <- "C:/Users/wb521633/OneDrive - WBG/PSV Rider Feedback"
}
# Tom (personal computer)
if(Sys.info()[["user"]] == "Tom"){
dropbox_dir <- "/Users/Tom/Dropbox/PSV Rider Feedback/"
github_dir <- "~/Google Drive/My Drive/Google Drive (iamtomharris98@gmail.com)/DIME 2/PSV-Rider-Feedback/"
}
# Ruiwen (WB Computer)
if(Sys.info()[["user"]] == "wb575963"){
dropbox_dir <- "C:/Users/wb575963/Dropbox/PSV Rider Feedback"
github_dir <- "C:/Users/wb575963/Github/PSV-Rider-Feedback/"
onedrive_dir <- "C:/Users/wb575963/WBG/Robert Andrew Marty - PSV Rider Feedback"
}
#### From Dropbox
data_dir                   <- file.path(dropbox_dir, "Data")
rider_feedback_dir         <- file.path(data_dir, "Rider Feedback")
sensors_dir                <- file.path(data_dir, "Sensor Data")
sensor_install_survey_dir  <- file.path(data_dir, "Matatu Sensor Installation Survey")
sticker_install_survey_dir <- file.path(data_dir, "Sticker Installation Survey")
sacco_route_dir            <- file.path(data_dir, "Sacco Route Data")
driver_message_dir         <- file.path(data_dir, "Send Messages to Drivers")
matatu_data_dir            <- file.path(data_dir, "Matatu Data")
ntsa_speed_dir             <- file.path(data_dir, "NTSA - Speed Data")
ap_data_dir <- file.path(dropbox_dir, "Academic Paper/Data")
brief_figures_dir <- file.path(dropbox_dir, "Policy Brief/figures")
#### Encrypted Data
data_pii_dir                   <- file.path(db_pii_dir, "Data")
rider_feedback_pii_dir         <- file.path(data_pii_dir, "Rider Feedback")
sticker_install_survey_pii_dir <- file.path(data_pii_dir, "Sticker Installation Survey")
# API Keys ---------------------------------------------------------------------
if(Sys.info()[["user"]] == "robmarty"){
api_keys_df <- read.csv(file.path("~/Dropbox", "World Bank", "Webscraping", "Files for Server", "api_keys.csv"),
stringsAsFactors = F)
}
# Packages ---------------------------------------------------------------------
library(tidyverse)
library(dplyr)
library(lubridate)
library(gridExtra)
library(hrbrthemes)
library(readxl)
library(labelled)
library(haven)
library(stringr)
library(rmarkdown)
library(wesanderson)
library(knitr)
library(data.table)
library(DT)
library(syn)
library(kableExtra)
library(openssl)
library(ggmap)
library(lubridate)
library(httr)
library(jsonlite)
library(arrow)
library(furrr)
library(geosphere)
library(sf)
library(sfheaders)
library(googlesheets4)
library(leaflet)
library(progress)
library(ggpubr)
library(twilio)
library(raster)
library(magick)
library(janitor)
library(qrcode)
library(scales)
# Functions --------------------------------------------------------------------
#source(file.path(github_dir, "DataWork", "Sensor Data", "01_clean_data", "_wialon_api_functions.R"))
source(file.path(github_dir, "Functions", "load_sensortracing_raw.R"))
source("https://raw.githubusercontent.com/ramarty/r_google_translate/main/r_google_translate.R")
# Code -------------------------------------------------------------------------
if(RUN_CODE){
# Process Sticker Installation Survey ----------------------------------------
sticker_install_survey_code_dir <- file.path(github_dir, "DataWork", "Sticker Installation Survey")
source(file.path(sticker_install_survey_code_dir, "01_clean_data.R"))
# Process Rider Feedback Data ------------------------------------------------
rider_feedback_code_dir <- file.path(github_dir, "DataWork", "Rider Feedback")
source(file.path(rider_feedback_code_dir, "01_clean_data.R"))
source(file.path(rider_feedback_code_dir, "02a_translate_comments.R"))
source(file.path(rider_feedback_code_dir, "02b_append_translated_comments.R"))
source(file.path(rider_feedback_code_dir, "03_merge_data.R"))
source(file.path(rider_feedback_code_dir, "04_create_comments_to_code.R"))
# Process Sensor Data --------------------------------------------------------
if(PROCESS_SENSOR_DATA){
sensor_code_dir <- file.path(github_dir, "DataWork", "Sensor Data", "01_clean_data")
# Check Wailon Token Still Valid
source(file.path(sensor_code_dir, "00_check_wialon_token.R"))
# Download Sensor Data
source(file.path(sensor_code_dir, "02_download_data.R"))
# Process Sensor Tracing Data
# A. Sensor data downloaded as json. Convert json to dataframe/export as
#    parquet file.
# B. Aggregate sensor data to hourly level and save file for each vehicle
#    and day (so file at hourly level for each vehilce and day). Saves file
#    with data including polyline of route and a separate smaller file
#    that just includes the data (with no polyline)
# C. Append sensor hourly data, creating file with all data appended.
source(file.path(sensor_code_dir, "03a_sensor_data_json_to_df.R"))
source(file.path(sensor_code_dir, "03b_sensor_to_hourly_individual_files.R"))
source(file.path(sensor_code_dir, "03c_append_sensor_hr_data.R"))
# Process Echo driving Data
source(file.path(sensor_code_dir, "04a_append_echodriving_raw.R"))
source(file.path(sensor_code_dir, "04a_echodriving_to_hourly_individual_files.R"))
source(file.path(sensor_code_dir, "04b_append_echodriving_hr_data.R"))
# Process Speed Data
source(file.path(sensor_code_dir, "05a_append_speedings_raw.R"))
source(file.path(sensor_code_dir, "05b_speedings_to_hr.R"))
# Create Day and Day/Hour data with sensor tracing + echo driving merged in
source(file.path(sensor_code_dir, "06_merge_dayhr_data.R"))
source(file.path(sensor_code_dir, "07_aggregate_to_daily.R"))
}
# Process Sensor Installation Survey -----------------------------------------
if(PROCESS_SENSOR_SURVEY_DATA){
sensor_survey_code_dir <- file.path(github_dir, "DataWork", "Matatu Sensor Installation Survey")
source(file.path(sensor_survey_code_dir, "02_clean_data.R"))
source(file.path(sensor_survey_code_dir, "03_check_all_surveys_entered_compare_wialon.R"))
}
}
# Crowdsourcing Safety Paper
RUN_CODE <- F
# Filepaths --------------------------------------------------------------------
# Rob (Personal Comptuer)
if(Sys.info()[["user"]] == "robmarty"){
db_dir <- "~/Dropbox/World Bank/IEs/PSV Rider Feedback"
data_dir <- "~/Dropbox/World Bank/IEs/PSV Rider Feedback/Academic Paper/Data"
git_dir  <- "~/Documents/Github/PSV-Rider-Feedback/Academic Paper"
overleaf_dir <- "~/Dropbox/Apps/Overleaf/Crowdsourcing Safety Kenya Matatu Passenger Safety Project"
}
# Ruiwen (WB Computer)
if(Sys.info()[["user"]] == "wb575963"){
db_dir <- "C:/Users/wb575963/Dropbox/PSV Rider Feedback"
data_dir <- "C:/Users/wb575963/Dropbox/PSV Rider Feedback/Academic Paper/Data"
git_dir <- "C:/Users/wb575963/Github/PSV-Rider-Feedback/Academic Paper"
}
tables_dir  <- file.path(overleaf_dir, "tables")
figures_dir <- file.path(overleaf_dir, "figures")
# Packages ---------------------------------------------------------------------
library(magrittr)
library(dplyr)
library(readr)
library(tidyr)
library(stringr)
library(lubridate)
library(ggplot2)
library(sf)
library(readxl)
library(janitor)
library(arrow)
library(quanteda)
library(wordcloud2)
library(tidytext)
library(sentimentr)
library(ggpubr)
library(DescTools)
library(forcats)
library(tm)
library(quanteda)
library(scales)
library(haven)
library(fixest)
library(purrr)
library(tibble)
library(did)
#library(cleanNLP)
#library(coreNLP)
# Parameters -------------------------------------------------------------------
DRIVING_WORDS <- "safe|drunk|accident|careless"
COVID_WORDS <- "covid|pandemic|mask|social distance|sanitizer|sanitiser"
# Run Code =====================================================================
if(RUN_CODE){
# Clean data -----------------------------------------------------------------
git_clean_data_dir <- file.path(git_dir, "01_clean_data")
source(file.path(git_clean_data_dir, "01_feedback_outliers.R"))
source(file.path(git_clean_data_dir, "02_classify_feedback.R"))
source(file.path(git_clean_data_dir, "03_make_vehicle_level_data.R"))
# Passenger feedback analysis ------------------------------------------------
git_feedback_dir <- file.path(git_dir, "02_analysis", "passenger_feedback_analysis")
source(file.path(git_feedback_dir, "ratings_sum_stats_table.R"))
source(file.path(git_feedback_dir, "ratings_vs_comments_indiv_boxplot.R"))
source(file.path(git_feedback_dir, "ratings_vs_comments_vehicle_scatter.R"))
source(file.path(git_feedback_dir, "safety_speed_v1_crosstab.R"))
source(file.path(git_feedback_dir, "safety_speed_v2_crosstab.R"))
source(file.path(git_feedback_dir, "sentiment_distribution.R"))
source(file.path(git_feedback_dir, "sentiment_vs_class.R"))
source(file.path(git_feedback_dir, "top_pos_neg_words.R"))
source(file.path(git_feedback_dir, "vehicle_indicators_distribution.R"))
# Telematics data analysis ---------------------------------------------------
git_telematics_dir <- file.path(git_dir, "02_analysis", "telematics_analysis")
source(file.path(git_telematics_dir, "compare_variables.R"))
source(file.path(git_telematics_dir, "indicator_distribution.R"))
source(file.path(git_telematics_dir, "indicator_sum_stat_table.R"))
# Telematics vs feedback analysis --------------------------------------------
git_tele_vs_feed_dir <- file.path(git_dir, "02_analysis", "telematics_vs_feedback")
source(file.path(git_tele_vs_feed_dir, "correlation_plot.R"))
source(file.path(git_tele_vs_feed_dir, "scatter_plots.R"))
}
# Crowdsourcing Safety Paper
RUN_CODE <- F
# Filepaths --------------------------------------------------------------------
# Rob (Personal Comptuer)
if(Sys.info()[["user"]] == "robmarty"){
db_dir <- "~/Dropbox/World Bank/IEs/PSV Rider Feedback"
data_dir <- "~/Dropbox/World Bank/IEs/PSV Rider Feedback/Academic Paper/Data"
git_dir  <- "~/Documents/Github/PSV-Rider-Feedback/Academic Paper"
overleaf_dir <- "~/Dropbox/Apps/Overleaf/Crowdsourcing Safety Kenya Matatu Passenger Safety Project"
}
# Ruiwen (WB Computer)
if(Sys.info()[["user"]] == "wb575963"){
db_dir <- "C:/Users/wb575963/Dropbox/PSV Rider Feedback"
data_dir <- "C:/Users/wb575963/Dropbox/PSV Rider Feedback/Academic Paper/Data"
git_dir <- "C:/Users/wb575963/Github/PSV-Rider-Feedback/Academic Paper"
}
tables_dir  <- file.path(overleaf_dir, "tables")
figures_dir <- file.path(overleaf_dir, "figures")
# Packages ---------------------------------------------------------------------
library(magrittr)
library(dplyr)
library(readr)
library(tidyr)
library(stringr)
library(lubridate)
library(ggplot2)
library(sf)
library(readxl)
library(janitor)
library(arrow)
library(quanteda)
library(wordcloud2)
library(tidytext)
library(sentimentr)
library(ggpubr)
library(DescTools)
library(forcats)
library(tm)
library(quanteda)
library(scales)
library(haven)
library(fixest)
library(purrr)
library(tibble)
library(did)
#library(cleanNLP)
#library(coreNLP)
# Parameters -------------------------------------------------------------------
DRIVING_WORDS <- "safe|drunk|accident|careless"
COVID_WORDS <- "covid|pandemic|mask|social distance|sanitizer|sanitiser"
# Run Code =====================================================================
if(RUN_CODE){
# Clean data -----------------------------------------------------------------
git_clean_data_dir <- file.path(git_dir, "01_clean_data")
source(file.path(git_clean_data_dir, "01_feedback_outliers.R"))
source(file.path(git_clean_data_dir, "02_classify_feedback.R"))
source(file.path(git_clean_data_dir, "03_make_vehicle_level_data.R"))
# Passenger feedback analysis ------------------------------------------------
git_feedback_dir <- file.path(git_dir, "02_analysis", "passenger_feedback_analysis")
source(file.path(git_feedback_dir, "ratings_sum_stats_table.R"))
source(file.path(git_feedback_dir, "ratings_vs_comments_indiv_boxplot.R"))
source(file.path(git_feedback_dir, "ratings_vs_comments_vehicle_scatter.R"))
source(file.path(git_feedback_dir, "safety_speed_v1_crosstab.R"))
source(file.path(git_feedback_dir, "safety_speed_v2_crosstab.R"))
source(file.path(git_feedback_dir, "sentiment_distribution.R"))
source(file.path(git_feedback_dir, "sentiment_vs_class.R"))
source(file.path(git_feedback_dir, "top_pos_neg_words.R"))
source(file.path(git_feedback_dir, "vehicle_indicators_distribution.R"))
# Telematics data analysis ---------------------------------------------------
git_telematics_dir <- file.path(git_dir, "02_analysis", "telematics_analysis")
source(file.path(git_telematics_dir, "compare_variables.R"))
source(file.path(git_telematics_dir, "indicator_distribution.R"))
source(file.path(git_telematics_dir, "indicator_sum_stat_table.R"))
# Telematics vs feedback analysis --------------------------------------------
git_tele_vs_feed_dir <- file.path(git_dir, "02_analysis", "telematics_vs_feedback")
source(file.path(git_tele_vs_feed_dir, "correlation_plot.R"))
source(file.path(git_tele_vs_feed_dir, "scatter_plots.R"))
}
# Crowdsourcing Safety Paper
RUN_CODE <- F
# Filepaths --------------------------------------------------------------------
# Rob (Personal Comptuer)
if(Sys.info()[["user"]] == "robmarty"){
db_dir <- "~/Dropbox/World Bank/IEs/PSV Rider Feedback"
data_dir <- "~/Dropbox/World Bank/IEs/PSV Rider Feedback/Academic Paper/Data"
git_dir  <- "~/Documents/Github/PSV-Rider-Feedback/Academic Paper"
overleaf_dir <- "~/Dropbox/Apps/Overleaf/Crowdsourcing Safety Kenya Matatu Passenger Safety Project"
}
# Ruiwen (WB Computer)
if(Sys.info()[["user"]] == "wb575963"){
db_dir <- "C:/Users/wb575963/Dropbox/PSV Rider Feedback"
data_dir <- "C:/Users/wb575963/Dropbox/PSV Rider Feedback/Academic Paper/Data"
git_dir <- "C:/Users/wb575963/Github/PSV-Rider-Feedback/Academic Paper"
}
tables_dir  <- file.path(overleaf_dir, "tables")
figures_dir <- file.path(overleaf_dir, "figures")
# Packages ---------------------------------------------------------------------
library(magrittr)
library(dplyr)
library(readr)
library(tidyr)
library(stringr)
library(lubridate)
library(ggplot2)
library(sf)
library(readxl)
library(janitor)
library(arrow)
library(quanteda)
library(wordcloud2)
library(tidytext)
library(sentimentr)
library(ggpubr)
library(DescTools)
library(forcats)
library(tm)
library(quanteda)
library(scales)
library(haven)
library(fixest)
library(purrr)
library(tibble)
library(did)
#library(cleanNLP)
#library(coreNLP)
# Parameters -------------------------------------------------------------------
DRIVING_WORDS <- "safe|drunk|accident|careless"
COVID_WORDS <- "covid|pandemic|mask|social distance|sanitizer|sanitiser"
# Run Code =====================================================================
if(RUN_CODE){
# Clean data -----------------------------------------------------------------
git_clean_data_dir <- file.path(git_dir, "01_clean_data")
source(file.path(git_clean_data_dir, "01_feedback_outliers.R"))
source(file.path(git_clean_data_dir, "02_classify_feedback.R"))
source(file.path(git_clean_data_dir, "03_make_vehicle_level_data.R"))
# Passenger feedback analysis ------------------------------------------------
git_feedback_dir <- file.path(git_dir, "02_analysis", "passenger_feedback_analysis")
source(file.path(git_feedback_dir, "ratings_sum_stats_table.R"))
source(file.path(git_feedback_dir, "ratings_vs_comments_indiv_boxplot.R"))
source(file.path(git_feedback_dir, "ratings_vs_comments_vehicle_scatter.R"))
source(file.path(git_feedback_dir, "safety_speed_v1_crosstab.R"))
source(file.path(git_feedback_dir, "safety_speed_v2_crosstab.R"))
source(file.path(git_feedback_dir, "sentiment_distribution.R"))
source(file.path(git_feedback_dir, "sentiment_vs_class.R"))
source(file.path(git_feedback_dir, "top_pos_neg_words.R"))
source(file.path(git_feedback_dir, "vehicle_indicators_distribution.R"))
# Telematics data analysis ---------------------------------------------------
git_telematics_dir <- file.path(git_dir, "02_analysis", "telematics_analysis")
source(file.path(git_telematics_dir, "compare_variables.R"))
source(file.path(git_telematics_dir, "indicator_distribution.R"))
source(file.path(git_telematics_dir, "indicator_sum_stat_table.R"))
# Telematics vs feedback analysis --------------------------------------------
git_tele_vs_feed_dir <- file.path(git_dir, "02_analysis", "telematics_vs_feedback")
source(file.path(git_tele_vs_feed_dir, "correlation_plot.R"))
source(file.path(git_tele_vs_feed_dir, "scatter_plots.R"))
}
