{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (2.32.5)\n",
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (2.3.3)\n",
      "Requirement already satisfied: geopandas in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (1.1.1)\n",
      "Requirement already satisfied: shapely in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (2.1.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests) (2.5.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests) (3.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests) (2025.10.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests) (3.4.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/toweramoyo/Library/Python/3.10/lib/python/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pandas) (2.2.6)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: pyproj>=3.5.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from geopandas) (3.7.1)\n",
      "Requirement already satisfied: pyogrio>=0.7.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from geopandas) (0.11.1)\n",
      "Requirement already satisfied: packaging in /Users/toweramoyo/Library/Python/3.10/lib/python/site-packages (from geopandas) (25.0)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.12.0)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 25.2 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install requests pandas geopandas shapely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Fetch Carbon Mapper CH4 plumes by bbox, clip to Myanmar ADM1 (HDX),\n",
    "apply a tolerance buffer (2–5 km), and output filtered results.\n",
    "\n",
    "Inputs:\n",
    "    - CARBONMAPPER_TOKEN  : environment variable with your Carbon Mapper API token\n",
    "    - HDX_ADM1_PATH       : path to HDX Myanmar Admin Level-1 (e.g., GeoJSON/Shapefile)\n",
    "\n",
    "Outputs:\n",
    "    - myanmar_ch4_plumes.csv : All CH4 plumes within Myanmar boundary\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import requests\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "from io import StringIO\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-15 12:35:36,143 INFO Fetching offset 0 …\n",
      "2025-10-15 12:35:37,539 INFO Got 143 rows\n",
      "2025-10-15 12:35:37,539 INFO Total downloaded: 143 plumes\n",
      "2025-10-15 12:35:37,573 INFO Valid coordinate rows: 143\n",
      "2025-10-15 12:35:39,651 INFO Plumes inside Myanmar (buffered 3.0 km): 12\n",
      "2025-10-15 12:35:39,665 INFO Saved: myanmar_ch4_plumes.csv\n",
      "2025-10-15 12:35:39,666 INFO Total plumes: 12\n"
     ]
    }
   ],
   "source": [
    "\n",
    "API_BASE = \"https://api.carbonmapper.org/api/v1\"\n",
    "\n",
    "# Enter token here\n",
    "API_TOKEN = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ0b2tlbl90eXBlIjoiYWNjZXNzIiwiZXhwIjoxNzYxMTI4MDczLCJpYXQiOjE3NjA1MjMyNzMsImp0aSI6ImYxYjc2MGUxN2IyMjQwZWFhOGU2ODMxYzNlY2VhZGQ5Iiwic2NvcGUiOiJzdGFjIGNhdGFsb2c6cmVhZCIsImdyb3VwcyI6IlB1YmxpYyIsImFsbF9ncm91cF9uYW1lcyI6eyJjb21tb24iOlsiUHVibGljIl19LCJvcmdhbml6YXRpb25zIjoiIiwic2V0dGluZ3MiOnt9LCJpc19zdGFmZiI6ZmFsc2UsImlzX3N1cGVydXNlciI6ZmFsc2UsInVzZXJfaWQiOjE2NjMzfQ.9t-Y1GMFxhlm9pjkUB7s7-6OpFA0wvwul-e14qBRwYY\"\n",
    "\n",
    "# Geographic bounds (Myanmar approximate bbox: [min_lon, min_lat, max_lon, max_lat])\n",
    "MYANMAR_BBOX = [92.15, 9.5, 101.15, 28.6]\n",
    "\n",
    "# HDX Myanmar Admin-1 boundary file path \n",
    "HDX_ADM1_PATH = \"./files/myanmar_admin_boundaries.json\"\n",
    "\n",
    "# Spatial tolerance buffer around Myanmar boundary (in kilometres)\n",
    "BUFFER_KM = 3.0\n",
    "\n",
    "# API pagination settings\n",
    "LIMIT = 1000\n",
    "TIMEOUT = 60\n",
    "\n",
    "# Safety cap for pagination (prevents runaway loops)\n",
    "MAX_RECORDS = 200000\n",
    "\n",
    "# Output file\n",
    "OUT_CSV = \"myanmar_ch4_plumes.csv\"\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s %(levelname)s %(message)s\",\n",
    ")\n",
    "logger = logging.getLogger(\"carbonmapper_mmr\")\n",
    "\n",
    "\n",
    "def build_session() -> requests.Session:\n",
    "    if not API_TOKEN or API_TOKEN.strip() == \"\":\n",
    "        logger.error(\"Set API_TOKEN in the script to your full Carbon Mapper JWT.\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    s = requests.Session()\n",
    "    s.headers.update({\n",
    "        \"Authorization\": f\"Bearer {API_TOKEN}\",\n",
    "        \"Accept\": \"text/csv\",\n",
    "    })\n",
    "    return s\n",
    "\n",
    "def fetch_chunk(session: requests.Session, offset: int) -> pd.DataFrame:\n",
    "    params = {\n",
    "        \"bbox\": MYANMAR_BBOX,\n",
    "        \"plume_gas\": \"CH4\",\n",
    "        \"limit\": LIMIT,\n",
    "        \"offset\": offset,\n",
    "    }\n",
    "    try:\n",
    "        r = session.get(\n",
    "            f\"{API_BASE}/catalog/plume-csv\",\n",
    "            params=params,\n",
    "            timeout=TIMEOUT,\n",
    "        )\n",
    "        r.raise_for_status()\n",
    "    except requests.RequestException as e:\n",
    "        msg = getattr(getattr(e, \"response\", None), \"text\", \"\")\n",
    "        logger.error(\n",
    "            \"API request failed at offset %s: %s%s\",\n",
    "            offset, str(e), f\" | Response: {msg[:300]}\" if msg else \"\"\n",
    "        )\n",
    "        sys.exit(1)\n",
    "\n",
    "    text = r.text.strip()\n",
    "    if not text:\n",
    "        return pd.DataFrame()\n",
    "    return pd.read_csv(StringIO(text))\n",
    "\n",
    "\n",
    "def load_admin_polygon(path: str, buffer_km: float) -> gpd.GeoDataFrame:\n",
    "    if not path or not os.path.exists(path):\n",
    "        raise FileNotFoundError(f\"Admin boundary file not found: {path!r}\")\n",
    "\n",
    "    admin = gpd.read_file(path)\n",
    "\n",
    "    # Normalise CRS to WGS84\n",
    "    if admin.crs is None:\n",
    "        admin = admin.set_crs(\"EPSG:4326\")\n",
    "    else:\n",
    "        admin = admin.to_crs(\"EPSG:4326\")\n",
    "\n",
    "    # Fix invalid geometries (common in real-world GIS data)\n",
    "    admin[\"geometry\"] = admin.buffer(0)\n",
    "\n",
    "    # Dissolve to a single polygon\n",
    "    admin[\"__all__\"] = 1\n",
    "    adm1_single = admin.dissolve(by=\"__all__\", as_index=False)[[\"geometry\"]]\n",
    "\n",
    "    # Buffer in metres via projected CRS, then return to WGS84\n",
    "    adm1_3857 = adm1_single.to_crs(3857)\n",
    "    adm1_3857[\"geometry\"] = adm1_3857.buffer(buffer_km * 1000.0)\n",
    "    return adm1_3857.to_crs(4326)\n",
    "\n",
    "\n",
    "def build_points_gdf(df: pd.DataFrame) -> gpd.GeoDataFrame:\n",
    "    lat_candidates = [\"plume_latitude\", \"latitude\", \"lat\"]\n",
    "    lon_candidates = [\"plume_longitude\", \"longitude\", \"lon\"]\n",
    "\n",
    "    lat_col = next((c for c in lat_candidates if c in df.columns), None)\n",
    "    lon_col = next((c for c in lon_candidates if c in df.columns), None)\n",
    "\n",
    "    if not lat_col or not lon_col:\n",
    "        raise ValueError(\n",
    "            f\"Could not find latitude/longitude columns in API data. \"\n",
    "            f\"Available columns: {df.columns.tolist()}\"\n",
    "        )\n",
    "\n",
    "    pts = df.copy()\n",
    "    pts[lat_col] = pd.to_numeric(pts[lat_col], errors=\"coerce\")\n",
    "    pts[lon_col] = pd.to_numeric(pts[lon_col], errors=\"coerce\")\n",
    "    pts = pts.dropna(subset=[lat_col, lon_col])\n",
    "\n",
    "    gdf = gpd.GeoDataFrame(\n",
    "        pts,\n",
    "        geometry=gpd.points_from_xy(pts[lon_col], pts[lat_col]),\n",
    "        crs=\"EPSG:4326\",\n",
    "    )\n",
    "    return gdf\n",
    "\n",
    "\n",
    "def main():\n",
    "    session = build_session()\n",
    "\n",
    "    # 1) Download plumes by bbox with pagination\n",
    "    chunks = []\n",
    "    offset = 0\n",
    "    fetched = 0\n",
    "\n",
    "    while True:\n",
    "        logger.info(\"Fetching offset %s …\", offset)\n",
    "        df_chunk = fetch_chunk(session, offset)\n",
    "        logger.info(\"Got %s rows\", len(df_chunk))\n",
    "\n",
    "        if df_chunk.empty:\n",
    "            break\n",
    "\n",
    "        chunks.append(df_chunk)\n",
    "        fetched += len(df_chunk)\n",
    "\n",
    "        if len(df_chunk) < LIMIT:\n",
    "            break\n",
    "\n",
    "        if fetched >= MAX_RECORDS:\n",
    "            logger.warning(\"Reached MAX_RECORDS cap (%s). Stopping pagination.\", MAX_RECORDS)\n",
    "            break\n",
    "\n",
    "        offset += LIMIT\n",
    "\n",
    "    if not chunks:\n",
    "        logger.info(\"No data downloaded from API.\")\n",
    "        sys.exit(0)\n",
    "\n",
    "    raw = pd.concat(chunks, ignore_index=True)\n",
    "    logger.info(\"Total downloaded: %s plumes\", len(raw))\n",
    "\n",
    "    # 2) Build GeoDataFrame of points\n",
    "    try:\n",
    "        gdf_pts = build_points_gdf(raw)\n",
    "    except ValueError as e:\n",
    "        logger.error(\"%s\", e)\n",
    "        sys.exit(1)\n",
    "    logger.info(\"Valid coordinate rows: %s\", len(gdf_pts))\n",
    "\n",
    "    # 3) Load admin boundary and apply buffer\n",
    "    try:\n",
    "        adm1 = load_admin_polygon(HDX_ADM1_PATH, BUFFER_KM)\n",
    "    except FileNotFoundError as e:\n",
    "        logger.error(\"%s\", e)\n",
    "        sys.exit(1)\n",
    "\n",
    "    # 4) Spatial join - keep only points inside buffered Myanmar\n",
    "    joined = gpd.sjoin(gdf_pts, adm1, how=\"inner\", predicate=\"within\")\n",
    "    kept = joined.drop(columns=[\"index_right\"], errors=\"ignore\")\n",
    "    logger.info(\"Plumes inside Myanmar (buffered %.1f km): %s\", BUFFER_KM, len(kept))\n",
    "\n",
    "    # 5) Deduplicate by plume_id if present\n",
    "    if \"plume_id\" in kept.columns:\n",
    "        before = len(kept)\n",
    "        kept = kept.drop_duplicates(subset=[\"plume_id\"])\n",
    "        removed = before - len(kept)\n",
    "        if removed > 0:\n",
    "            logger.info(\"Removed %s duplicate plume_id(s). Final: %s unique plumes\", removed, len(kept))\n",
    "    else:\n",
    "        logger.warning(\"Column 'plume_id' not found; skipping deduplication.\")\n",
    "\n",
    "    # 6) Save output\n",
    "    kept_csv = kept.drop(columns=[\"geometry\"], errors=\"ignore\")\n",
    "    kept_csv.to_csv(OUT_CSV, index=False)\n",
    "    logger.info(\"Saved: %s\", OUT_CSV)\n",
    "    logger.info(\"Total plumes: %s\", len(kept_csv))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
